# HOI4D 数据集详细描述

## 1. 数据集概述

HOI4D 是一个大规模4D以自我为中心的数据集，专注于类别级人-物交互（HOI）研究。其核心特点包括：

- **数据规模**：包含2.4M RGB-D视频帧，4000+序列，覆盖800个不同物体实例（16个类别）和610个室内场景。
- **多模态标注**：提供逐帧的动作分割、运动分割、3D手部姿态、类别级物体姿态、全景分割等丰富标注。
- **4D数据**：RGB-D视频（3D空间+时间序列）记录动态交互过程。
- **重建模型**：包含物体CAD模型（.obj文件）和场景点云，支持铰接物体（如带手柄的杯子）的运动链定义。

---

## 2. 数据采集设备

| 设备类型               | 型号                     | 用途                     |
|------------------------|--------------------------|--------------------------|
| RGB-D传感器            | Kinect v2                | 采集RGB-D视频与深度信息  |
| RGB-D传感器            | Intel RealSense D455     | 高精度RGB-D数据采集      |

---

## 3. 数据内容与结构

### 3.1 数据架构
HOI4D采用层级化存储结构，核心路径遵循：
`/相机ID/参与者ID/类别ID/实例ID/场景ID/任务ID/`  
每个终端节点包含：
- 多模态原始数据（RGB-D视频流）
- 时空对齐的标注数据
- 几何重建资源（点云/Mesh）

### 3.2 核心标识
**关键维度**：
- **物体标识**：`C*_N*`（16类×800实例）
- **交互上下文**：`H*_T*`（9人×多任务）
- **时空基准**：`ZY*_S*`（设备×场景）

**数据实体**：
- 动态流：同步RGB-D序列（720P@30fps）
- 静态资产：CAD模型+场景点云
- 标注层：姿态/分割/动作三位一体标注


## 4. 关键文件说明

### 4.1 物体模型相关文件

| 文件名            | 内容描述                                                                 | 示例用途                     |
|-------------------|--------------------------------------------------------------------------|------------------------------|
| `meta.json`       | 记录模型元信息（用户、类别、版本等）                                     | 模型管理与版本追踪           |
| `mobility_v2.json`| 定义铰接物体运动链（如手柄旋转轴、角度限制）                             | 物理仿真与动画生成           |
| `result.json`     | 描述模型层级结构（父子部件关系）及关联的3D对象（如杯身`new-1`）          | 场景组装与渲染               |

### 4.2 标注文件示例

#### 动作分割（`action/color.json`）
```json
{
  "duration": 10.5,
  "event": "pour",
  "startTime": 2.1,
  "endTime": 5.3
}
```
## 5. 核心应用场景

### 5.1 学术研究
- **交互行为理解**
  - 抓握/操作/使用等动作识别
  - 铰接物体(如带手柄杯子)姿态估计
  - 动态场景的4D语义分割

### 5.2 工业落地
- **机器人技能学习**
  - 基于真实交互的抓取策略训练
  - 复杂操作任务模仿学习

- **XR内容生成**
  - 虚拟交互场景重建
  - 沉浸式训练系统开发