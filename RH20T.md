# RH20T 数据集详细描述

## 1. 数据集概述
- **RH20T**  
  - **规模**: 20TB，包含超过110,000个接触丰富的机器人操作序列  
  - **技能覆盖**: 近150种不同技能（含48个RLBench任务、29个MetaWorld任务及70个自研任务）  
  - **模态**: 多模态数据（视觉、触觉、力觉、音频、动作信息）  
  - **特点**: 现实世界采集、多传感器校准、时间同步  
  - **目标**: 支持一次性模仿学习与多模态感知泛化  

- **RH20T-P**  
  - **规模**: 约33,000个视频片段  
  - **任务覆盖**: 44种复杂任务  
  - **标注**: 人工标注原始技能（基于运动与夹持器状态）  
  - **特点**: 可组合泛化、精细空间信息  
  - **目标**: 促进可组合泛化代理（CGA）开发  

---

## 2. 数据采集设备
| **传感器/设备**       | **规格/参数**                     | **频率**   | **备注**                          |
|-----------------------|----------------------------------|------------|-----------------------------------|
| RGB相机               | 1280×720×3                      | 10Hz       | 多视角同步采集                    |
| 深度相机              | 1280×720像素                    | 10Hz       |                                   |
| 双目红外相机          | 2×1280×720                      | 10Hz       |                                   |
| 机器人关节角度        | 6/7维（依机器人类型）            | 10Hz       |                                   |
| 机器人关节扭矩        | 6/7维                           | 10Hz       |                                   |
| 夹持器笛卡尔位姿      | 6/7维                           | 100Hz      |                                   |
| 6-DoF力/扭矩传感器    | 6维                             | 100Hz      | 基坐标系对齐                      |
| 音频设备              | -                               | 30Hz       |                                   |
| 指尖触觉传感器        | 2×16×3阵列                      | 200Hz      | 仅特定机器人配置（Cfg.7）支持     |

---

## 3. 数据内容与结构
### RH20T
- **序列结构**:  
  - 每个任务序列包含：  
    - 视觉数据（RGB-D、红外图像）  
    - 机器人状态（关节角度、扭矩、夹持器位姿）  
    - 力觉/触觉数据  
    - 音频记录  
    - 对应人类演示视频  
  - 时间同步：所有传感器数据通过时间戳对齐  

- **文件类型**:  
  - 原始视频（MP4格式）  
  - 校准文件（JSON/YAML）  
  - 时间戳索引文件  

### RH20T-P
- **标注结构**:  
  - 每个视频片段标注为原始技能序列：  
    - **基于运动的技能**（如轨迹跟踪）  
    - **基于夹持器的技能**（如抓取/释放）  
  - 附加空间信息（目标位置、工具使用上下文）  

---

## 4. 关键文件说明
| **文件/工具**         | **用途**                                | **路径/依赖**                     |
|-----------------------|----------------------------------------|-----------------------------------|
| `configs/configs.json` | 机器人配置信息（传感器参数、坐标系）    | `rh20t_api/configurations.py`     |
| `extract.py`          | RGB-D数据转原始图像格式                | 需运行`pip install -r requirements_api.txt` |
| `RH20TScene`类        | 加载场景数据（多模态同步访问）          | `rh20t_api/scene.py`              |
| `RH20TOnline`类       | 在线力觉/位姿数据投影到相机坐标系       | `rh20t_api/online.py`             |

---

## 5. 数据应用场景
- **研究领域**:  
  - 一次性模仿学习（One-shot Imitation Learning）  
  - 多模态感知融合（视觉+触觉）  
  - 可组合泛化代理（CGA）开发  
  

- **实际应用**:  

| **场景**       | **用例**                             | **数据集支持**                     |
|----------------|--------------------------------------|-----------------------------------|
| 工业制造       | 复杂装配、工具使用                   | RH20T-P原始技能分解               |
| 智能家居       | 长期规划任务（清洁、烹饪）           | RH20T多模态数据                   |
| 医疗机器人     | 手术器械操作、力反馈控制             | RH20T触觉与力觉数据               |
| 远程操作       | 直观遥操作界面开发                   | RH20T人类演示视频                 |
| 服务机器人     | 物体抓取与放置                       | RH20T-P空间标注与运动规划         |
| 农业自动化     | 果实采摘、精细操作                   | RH20T接触力与视觉融合数据         |     |